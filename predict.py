""" generates melody using trained LSTM """
import numpy as np
from keras.layers import LSTM
from keras.layers import Dropout
from keras.layers import Dense
from keras.layers import Activation
from keras.models import Sequential
import pickle
from music21 import instrument, note, stream, chord

def generate():
    with open('data/notes', 'rb') as filepath:
        notes = pickle.load(filepath)
    pitchnames = sorted(set(item for item in notes)) # Get all pitch names
    network_input, normalized_input = prepare_sequences(notes, pitchnames)
    model = create_network(normalized_input, len(set(notes)))
    prediction_output = generate_notes(model, network_input, pitchnames, len(set(notes)))
    create_midi(prediction_output)

def prepare_sequences(notes, pitchnames):
    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))
    sequence_length = 160
    network_input = []
    # network_output = []
    for i in range(0, len(notes) - sequence_length, 1):
        sequence_in = notes[i:i + sequence_length]
        # sequence_out = notes[i + sequence_length]
        network_input.append([note_to_int[char] for char in sequence_in])
        # network_output.append(note_to_int[sequence_out])
    n_patterns = len(network_input)
    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1)) # reshape the input into a format compatible with LSTM layers
    normalized_input = normalized_input/float(len(set(notes)))
    return (network_input, normalized_input)

def create_network(network_input, n_vocab):
    model = Sequential()
    model.add(LSTM(
        512,
        input_shape=(network_input.shape[1], network_input.shape[2]),
        return_sequences=True
    ))
    model.add(Dropout(0.4))
    model.add(LSTM(512, return_sequences=True))
    model.add(Dropout(0.4))
    model.add(LSTM(512))
    model.add(Dense(256))
    model.add(Dropout(0.4))
    model.add(Dense(n_vocab))
    model.add(Activation('softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
    model.load_weights('weights.hdf5') # load trained weights into the network
    return model

def generate_notes(model, network_input, pitchnames, n_vocab):
    start_seq = np.random.randint(0, len(network_input)-1) # pick a random input sequence as a starting point for the prediction
    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))
    pattern = network_input[start_seq]
    prediction_output = []
    for i in range(1000): # generate 1000 notes
        prediction_input = np.reshape(pattern, (1, len(pattern), 1))
        prediction_input = prediction_input/float(n_vocab)
        prediction = model.predict(prediction_input, verbose=0)
        index = np.argmax(prediction)
        result = int_to_note[index]
        prediction_output.append(result)
        pattern.append(index)
        pattern = pattern[1:] # add & shift one note at a time
    return prediction_output

def create_midi(prediction_output):
    """ convert the output from the prediction to notes and create a midi file
        from the notes """
    offset = 0
    output_notes = []
    # create note and chord objects based on the values generated by the model
    for note_chord in prediction_output: # note or chord
        if ('.' in note_chord) or note_chord.isdigit(): # is chord
            notes_in_chord = note_chord.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
        else: # is note
            new_note = note.Note(note_chord)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)
        offset += 0.25 # increase offset each iteration so that notes do not stack
    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp='test_prediction_output.mid')

if __name__ == '__main__':
    generate()

# code adapted from https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5%3Fsource%3Dquote_menu--------------------------respond_text&referrer=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5&originalAction=quote-respond&source=quote_menu--------------------------respond_text